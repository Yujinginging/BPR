{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (confusion_matrix,precision_score,recall_score,f1_score,\n",
    "    roc_curve,roc_auc_score,precision_recall_curve,accuracy_score,classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thick-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xyz(fileName):\n",
    "    \n",
    "    xyz_coordinates = [] #put xyz in an array\n",
    "    \n",
    "    with open(fileName,\"r\") as file:\n",
    "        for line_number,line in enumerate(file):\n",
    "            x,y,z = line.split()\n",
    "            \n",
    "            xyz_coordinates.append([int(x),int(y),float(z)])\n",
    "    return xyz_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vocational-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "groundwater_map = read_xyz(\"GRW_MBS_50m.xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "female-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display in dataframe \n",
    "#add cplumns of name\n",
    "my_array = np.array(groundwater_map)\n",
    "\n",
    "df = pd.DataFrame(my_array, columns = ['XKoordinat','YKoordinat','Depth'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-sensitivity",
   "metadata": {},
   "source": [
    "Now we have a table with x,y coordinates and depths. Next step is to copmare with csv file coordinates and get a column to state the ground water level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-alliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hispanic-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Energi_Viborg_Dandas_data.csv\")\n",
    "\n",
    "#drop columns not needed after asking the company about the meaning of these features\n",
    "\n",
    "columns_to_be_removed = [ 'mslink','LedningID','Dobbeltled','EjerKompon','SystemKode','KategoriAf','DatoUdf']\n",
    "data=data.drop(columns_to_be_removed,axis='columns')\n",
    "\n",
    "# in the column DatoSaneri is the date of repairing and if there is no date it means it is not repaired\n",
    "\n",
    "data['DatoSaneri'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "speaking-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only the pipes that are broken(by TV insection) now and the repaired ones\n",
    "\n",
    "data_with_TVObsAndSaneri = data[data['TVObsKode'].isin([1]) | data['DatoSaneri'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-ordinary",
   "metadata": {},
   "source": [
    "get matched depth withground water of broken pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "verified-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_depth(select_x,select_y):\n",
    "#     select_x = data['XKoordinat']\n",
    "#     select_y = data['YKoordinat']\n",
    "    #select_y = data.loc[data['XKoordinat'] == select_x]['YKoordinat'].values[0]\n",
    "    length = data_with_TVObsAndSaneri.loc[data_with_TVObsAndSaneri['XKoordinat'] == select_x]['Laengde'].values[0]\n",
    "    angle = data_with_TVObsAndSaneri.loc[data_with_TVObsAndSaneri['XKoordinat'] == select_x]['Fald'].values[0]\n",
    "#     length=data['Laengde']\n",
    "#     angle = data['Fald']\n",
    "    #calculate another point by length:\n",
    "    end_x = select_x+ (length * np.cos(angle))\n",
    "    end_y = select_y+ (length * np.sin(angle))\n",
    "    if(end_x > select_x):\n",
    "        max_x=end_x\n",
    "        min_x=select_x\n",
    "    else:\n",
    "        min_x=end_x\n",
    "        max_x=select_x   \n",
    "    if(end_y > select_y):\n",
    "        max_y=end_y\n",
    "        min_y=select_y\n",
    "    else:\n",
    "        min_y=end_y\n",
    "        max_y=select_y   \n",
    "\n",
    "\n",
    "    matched_depth_col = df.loc[(df['XKoordinat'] <= max_x)&(df['XKoordinat'] >= min_x)\n",
    "    &(df['YKoordinat'] <= max_y)&(df['YKoordinat'] >= min_y)]['Depth']\n",
    "    #test if there is a value\n",
    "    if(matched_depth_col.size > 0):\n",
    "        matched_depth = matched_depth_col.values[0]\n",
    "    else:\n",
    "        matched_depth = np.NaN\n",
    "    \n",
    "    return matched_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "republican-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>XKoordinat</th>\n",
       "      <th>YKoordinat</th>\n",
       "      <th>fra_kote</th>\n",
       "      <th>til_kote</th>\n",
       "      <th>Laengde</th>\n",
       "      <th>Fald</th>\n",
       "      <th>DiameterIn</th>\n",
       "      <th>MaterialeK</th>\n",
       "      <th>anlag_aar</th>\n",
       "      <th>TransportK</th>\n",
       "      <th>Funktionsk</th>\n",
       "      <th>TVObsKode</th>\n",
       "      <th>DatoOprett</th>\n",
       "      <th>DatoOpdate</th>\n",
       "      <th>DatoSaneri</th>\n",
       "      <th>Depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>87810</td>\n",
       "      <td>529911.05</td>\n",
       "      <td>6252443.83</td>\n",
       "      <td>34.720000</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>64.88</td>\n",
       "      <td>19.112207</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>87832</td>\n",
       "      <td>530405.37</td>\n",
       "      <td>6252578.04</td>\n",
       "      <td>39.460000</td>\n",
       "      <td>39.160000</td>\n",
       "      <td>91.75</td>\n",
       "      <td>3.269755</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.314121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>87834</td>\n",
       "      <td>530493.05</td>\n",
       "      <td>6252579.67</td>\n",
       "      <td>39.710000</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>87.69</td>\n",
       "      <td>2.622876</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>87901</td>\n",
       "      <td>530791.62</td>\n",
       "      <td>6252572.03</td>\n",
       "      <td>40.550000</td>\n",
       "      <td>40.080000</td>\n",
       "      <td>52.11</td>\n",
       "      <td>9.019382</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.478954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>87903</td>\n",
       "      <td>530857.05</td>\n",
       "      <td>6252552.13</td>\n",
       "      <td>40.380000</td>\n",
       "      <td>40.550000</td>\n",
       "      <td>68.39</td>\n",
       "      <td>-2.485744</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.462685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23957</th>\n",
       "      <td>222195</td>\n",
       "      <td>500582.01</td>\n",
       "      <td>6260561.72</td>\n",
       "      <td>11.940000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>60.32</td>\n",
       "      <td>23.043767</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.960063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24062</th>\n",
       "      <td>222448</td>\n",
       "      <td>544401.67</td>\n",
       "      <td>6256588.02</td>\n",
       "      <td>25.720000</td>\n",
       "      <td>22.820000</td>\n",
       "      <td>44.37</td>\n",
       "      <td>65.359477</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24073</th>\n",
       "      <td>222942</td>\n",
       "      <td>530696.61</td>\n",
       "      <td>6245426.58</td>\n",
       "      <td>28.490000</td>\n",
       "      <td>27.730000</td>\n",
       "      <td>84.29</td>\n",
       "      <td>9.016491</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24090</th>\n",
       "      <td>222967</td>\n",
       "      <td>530819.00</td>\n",
       "      <td>6245345.46</td>\n",
       "      <td>27.162706</td>\n",
       "      <td>27.902884</td>\n",
       "      <td>18.82</td>\n",
       "      <td>-39.329328</td>\n",
       "      <td>315.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24127</th>\n",
       "      <td>223151</td>\n",
       "      <td>519201.08</td>\n",
       "      <td>6263360.29</td>\n",
       "      <td>4.930000</td>\n",
       "      <td>3.180000</td>\n",
       "      <td>113.13</td>\n",
       "      <td>15.468930</td>\n",
       "      <td>191.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5.238400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2077 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  XKoordinat  YKoordinat   fra_kote   til_kote  Laengde  \\\n",
       "36      87810   529911.05  6252443.83  34.720000  33.480000    64.88   \n",
       "42      87832   530405.37  6252578.04  39.460000  39.160000    91.75   \n",
       "43      87834   530493.05  6252579.67  39.710000  39.480000    87.69   \n",
       "64      87901   530791.62  6252572.03  40.550000  40.080000    52.11   \n",
       "65      87903   530857.05  6252552.13  40.380000  40.550000    68.39   \n",
       "...       ...         ...         ...        ...        ...      ...   \n",
       "23957  222195   500582.01  6260561.72  11.940000  10.550000    60.32   \n",
       "24062  222448   544401.67  6256588.02  25.720000  22.820000    44.37   \n",
       "24073  222942   530696.61  6245426.58  28.490000  27.730000    84.29   \n",
       "24090  222967   530819.00  6245345.46  27.162706  27.902884    18.82   \n",
       "24127  223151   519201.08  6263360.29   4.930000   3.180000   113.13   \n",
       "\n",
       "            Fald  DiameterIn  MaterialeK  anlag_aar  TransportK  Funktionsk  \\\n",
       "36     19.112207       300.0         1.0     1939.0           1           0   \n",
       "42      3.269755       400.0         1.0     1939.0           1           0   \n",
       "43      2.622876       300.0         1.0     1939.0           1           0   \n",
       "64      9.019382       250.0         1.0     1945.0           1           0   \n",
       "65     -2.485744       250.0         1.0     1945.0           1           0   \n",
       "...          ...         ...         ...        ...         ...         ...   \n",
       "23957  23.043767       350.0         1.0     1968.0           1           0   \n",
       "24062  65.359477       160.0         4.0     2017.0           1           0   \n",
       "24073   9.016491       200.0         1.0     1995.0           1           0   \n",
       "24090 -39.329328       315.0         4.0     1965.0           1           0   \n",
       "24127  15.468930       191.0         4.0     1992.0           1           0   \n",
       "\n",
       "       TVObsKode  DatoOprett  DatoOpdate  DatoSaneri     Depth  \n",
       "36           0.0        2010        2014      1997.0       NaN  \n",
       "42           1.0        2010        2014         0.0  2.314121  \n",
       "43           1.0        2010        2014         0.0       NaN  \n",
       "64           1.0        2010        2014         0.0  4.478954  \n",
       "65           1.0        2010        2014         0.0  5.462685  \n",
       "...          ...         ...         ...         ...       ...  \n",
       "23957        1.0        2018        2018         0.0  9.960063  \n",
       "24062        1.0        2018        2018         0.0       NaN  \n",
       "24073        1.0        2018        2018         0.0       NaN  \n",
       "24090        1.0        2018        2018         0.0       NaN  \n",
       "24127        0.0        2018        2018      2018.0  5.238400  \n",
       "\n",
       "[2077 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_depth(datacopy):\n",
    "    select_x = datacopy['XKoordinat']\n",
    "    select_y = datacopy['YKoordinat']\n",
    "    return get_matched_depth(select_x,select_y)\n",
    "data_with_TVObsAndSaneri['Depth'] = data_with_TVObsAndSaneri.apply(add_depth,axis =1)\n",
    "data_with_TVObsAndSaneri    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "modular-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_TVObsAndSaneri_Groundwater = data_with_TVObsAndSaneri.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-cinema",
   "metadata": {},
   "source": [
    "handle unbroken pipe by adding groundwater depth and get around 619 rows randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "former-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_not_broken = data[~data['TVObsKode'].isin([0]) | data['DatoSaneri'] == 0]\n",
    "data_not_broken = data_not_broken.sample(n=4000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "earned-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_depth_unbroken(select_x,select_y):\n",
    "#     select_x = data['XKoordinat']\n",
    "#     select_y = data['YKoordinat']\n",
    "    #select_y = data.loc[data['XKoordinat'] == select_x]['YKoordinat'].values[0]\n",
    "    length = data_not_broken.loc[data_not_broken['XKoordinat'] == select_x]['Laengde'].values[0]\n",
    "    angle = data_not_broken.loc[data_not_broken['XKoordinat'] == select_x]['Fald'].values[0]\n",
    "#     length=data['Laengde']\n",
    "#     angle = data['Fald']\n",
    "    #calculate another point by length:\n",
    "    end_x = select_x+ (length * np.cos(angle))\n",
    "    end_y = select_y+ (length * np.sin(angle))\n",
    "    if(end_x > select_x):\n",
    "        max_x=end_x\n",
    "        min_x=select_x\n",
    "    else:\n",
    "        min_x=end_x\n",
    "        max_x=select_x   \n",
    "    if(end_y > select_y):\n",
    "        max_y=end_y\n",
    "        min_y=select_y\n",
    "    else:\n",
    "        min_y=end_y\n",
    "        max_y=select_y   \n",
    "\n",
    "\n",
    "    matched_depth_col = df.loc[(df['XKoordinat'] <= max_x)&(df['XKoordinat'] >= min_x)\n",
    "    &(df['YKoordinat'] <= max_y)&(df['YKoordinat'] >= min_y)]['Depth']\n",
    "    #test if there is a value\n",
    "    if(matched_depth_col.size > 0):\n",
    "        matched_depth = matched_depth_col.values[0]\n",
    "    else:\n",
    "        matched_depth = np.NaN\n",
    "    \n",
    "    return matched_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "competitive-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_depth_unbroken(datacopy):\n",
    "    select_x = datacopy['XKoordinat']\n",
    "    select_y = datacopy['YKoordinat']\n",
    "    return get_matched_depth_unbroken(select_x,select_y)\n",
    "data_not_broken['Depth'] = data_not_broken.apply(add_depth_unbroken,axis =1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unsigned-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_not_broken_Groundwater = data_not_broken.dropna()\n",
    "data_not_broken_Groundwater =data_not_broken_Groundwater.sample(n=619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hybrid-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data_not_broken_Groundwater,data_with_TVObsAndSaneri_Groundwater]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imported-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy = data\n",
    "\n",
    "\n",
    "# add  age column\n",
    "\n",
    "#get current year\n",
    "from datetime import date\n",
    "now = date.today().year\n",
    "\n",
    "\n",
    "def age_df(datacopy):\n",
    "\n",
    "    if (datacopy['TVObsKode'] == 1) and (datacopy['DatoSaneri'] > 0) :\n",
    "        return (now - datacopy['DatoSaneri'])\n",
    "    elif (datacopy['TVObsKode'] == 1) and (datacopy['DatoSaneri']== 0):\n",
    "        return (now - datacopy['anlag_aar'])\n",
    "    elif (datacopy['TVObsKode'] == 0) and (datacopy['DatoSaneri'] > 0):\n",
    "        return (now - datacopy['DatoSaneri'])\n",
    "    elif (datacopy['TVObsKode']== 0) and (datacopy['DatoSaneri']== 0):\n",
    "        return (now - datacopy['anlag_aar'])\n",
    "\n",
    "datacopy['Age'] = datacopy.apply(age_df, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "statewide-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column 'PipeStatus'\n",
    "# 1 as broken and 0 as not broken\n",
    "\n",
    "def broken_df(datacopy):\n",
    "\n",
    "    if (datacopy['TVObsKode'] == 1) and (datacopy['DatoSaneri'] < (datacopy['DatoOpdate'])) and (datacopy['DatoSaneri'] != 0):\n",
    "        return 1\n",
    "    elif (datacopy['TVObsKode'] == 1) and (datacopy['DatoSaneri'] >= (datacopy['DatoOpdate'])) and (datacopy['DatoSaneri'] != 0):\n",
    "        return 0\n",
    "    elif (datacopy['TVObsKode'] == 1) and (datacopy['DatoSaneri']== 0):\n",
    "        return 1\n",
    "    elif (datacopy['TVObsKode'] == 0) and (datacopy['DatoSaneri'] > 0):\n",
    "        return 0\n",
    "    elif (datacopy['TVObsKode']== 0) and (datacopy['DatoSaneri']== 0):\n",
    "        return 0\n",
    "\n",
    "datacopy['PipeStatus'] = datacopy.apply(broken_df, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spanish-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing NaNs: 1238\n",
      "Number of rows after removing NaNs: 1238\n"
     ]
    }
   ],
   "source": [
    "# data_fs= np.where(np.isnan(data_features))\n",
    "# data_fs\n",
    "print(\"Number of rows before removing NaNs: {}\".format(datacopy.shape[0]))\n",
    "datacopy = datacopy.dropna()\n",
    "print(\"Number of rows after removing NaNs: {}\".format(datacopy.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "specified-option",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>XKoordinat</th>\n",
       "      <th>YKoordinat</th>\n",
       "      <th>fra_kote</th>\n",
       "      <th>til_kote</th>\n",
       "      <th>Laengde</th>\n",
       "      <th>Fald</th>\n",
       "      <th>DiameterIn</th>\n",
       "      <th>MaterialeK</th>\n",
       "      <th>anlag_aar</th>\n",
       "      <th>TransportK</th>\n",
       "      <th>Funktionsk</th>\n",
       "      <th>TVObsKode</th>\n",
       "      <th>DatoSaneri</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Age</th>\n",
       "      <th>PipeStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>158854</td>\n",
       "      <td>521849.18</td>\n",
       "      <td>6251517.28</td>\n",
       "      <td>24.82</td>\n",
       "      <td>24.74</td>\n",
       "      <td>29.26</td>\n",
       "      <td>2.734108</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.945337</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>101958</td>\n",
       "      <td>546359.92</td>\n",
       "      <td>6262424.76</td>\n",
       "      <td>49.04</td>\n",
       "      <td>47.87</td>\n",
       "      <td>65.42</td>\n",
       "      <td>17.884439</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.740685</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23927</th>\n",
       "      <td>221915</td>\n",
       "      <td>529605.26</td>\n",
       "      <td>6255184.28</td>\n",
       "      <td>23.74</td>\n",
       "      <td>22.38</td>\n",
       "      <td>84.20</td>\n",
       "      <td>16.152019</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.261030</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>188135</td>\n",
       "      <td>515988.97</td>\n",
       "      <td>6243579.79</td>\n",
       "      <td>64.40</td>\n",
       "      <td>64.19</td>\n",
       "      <td>51.24</td>\n",
       "      <td>4.098361</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.591042</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15858</th>\n",
       "      <td>180964</td>\n",
       "      <td>539426.26</td>\n",
       "      <td>6248453.71</td>\n",
       "      <td>26.01</td>\n",
       "      <td>24.48</td>\n",
       "      <td>36.51</td>\n",
       "      <td>41.906327</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.070298</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23825</th>\n",
       "      <td>221075</td>\n",
       "      <td>505295.19</td>\n",
       "      <td>6253688.34</td>\n",
       "      <td>41.00</td>\n",
       "      <td>40.24</td>\n",
       "      <td>77.12</td>\n",
       "      <td>9.854772</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.129904</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23835</th>\n",
       "      <td>221099</td>\n",
       "      <td>505487.19</td>\n",
       "      <td>6253719.27</td>\n",
       "      <td>40.77</td>\n",
       "      <td>40.36</td>\n",
       "      <td>57.64</td>\n",
       "      <td>7.113116</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.236778</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23838</th>\n",
       "      <td>221112</td>\n",
       "      <td>505553.82</td>\n",
       "      <td>6253730.01</td>\n",
       "      <td>41.26</td>\n",
       "      <td>40.78</td>\n",
       "      <td>67.49</td>\n",
       "      <td>7.112165</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.404106</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23841</th>\n",
       "      <td>221115</td>\n",
       "      <td>505234.88</td>\n",
       "      <td>6253724.12</td>\n",
       "      <td>42.49</td>\n",
       "      <td>41.53</td>\n",
       "      <td>109.15</td>\n",
       "      <td>8.795236</td>\n",
       "      <td>315.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.049837</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23957</th>\n",
       "      <td>222195</td>\n",
       "      <td>500582.01</td>\n",
       "      <td>6260561.72</td>\n",
       "      <td>11.94</td>\n",
       "      <td>10.55</td>\n",
       "      <td>60.32</td>\n",
       "      <td>23.043767</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.960063</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1237 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  XKoordinat  YKoordinat  fra_kote  til_kote  Laengde       Fald  \\\n",
       "13255  158854   521849.18  6251517.28     24.82     24.74    29.26   2.734108   \n",
       "2618   101958   546359.92  6262424.76     49.04     47.87    65.42  17.884439   \n",
       "23927  221915   529605.26  6255184.28     23.74     22.38    84.20  16.152019   \n",
       "16996  188135   515988.97  6243579.79     64.40     64.19    51.24   4.098361   \n",
       "15858  180964   539426.26  6248453.71     26.01     24.48    36.51  41.906327   \n",
       "...       ...         ...         ...       ...       ...      ...        ...   \n",
       "23825  221075   505295.19  6253688.34     41.00     40.24    77.12   9.854772   \n",
       "23835  221099   505487.19  6253719.27     40.77     40.36    57.64   7.113116   \n",
       "23838  221112   505553.82  6253730.01     41.26     40.78    67.49   7.112165   \n",
       "23841  221115   505234.88  6253724.12     42.49     41.53   109.15   8.795236   \n",
       "23957  222195   500582.01  6260561.72     11.94     10.55    60.32  23.043767   \n",
       "\n",
       "       DiameterIn  MaterialeK  anlag_aar  TransportK  Funktionsk  TVObsKode  \\\n",
       "13255       300.0         1.0     1943.0           1           0        0.0   \n",
       "2618        160.0         4.0     1999.0           1           0        0.0   \n",
       "23927       250.0         4.0     2018.0           1           0        0.0   \n",
       "16996       300.0         1.0     1969.0           1           0        0.0   \n",
       "15858       200.0         4.0     2001.0           1           0        0.0   \n",
       "...           ...         ...        ...         ...         ...        ...   \n",
       "23825       200.0         1.0     1979.0           1           0        1.0   \n",
       "23835       200.0         1.0     1979.0           1           0        1.0   \n",
       "23838       200.0         1.0     1979.0           1           0        1.0   \n",
       "23841       315.0         4.0     1992.0           1           0        1.0   \n",
       "23957       350.0         1.0     1968.0           1           0        1.0   \n",
       "\n",
       "       DatoSaneri      Depth   Age  PipeStatus  \n",
       "13255         0.0  12.945337  78.0           0  \n",
       "2618          0.0   8.740685  22.0           0  \n",
       "23927         0.0   8.261030   3.0           0  \n",
       "16996         0.0  20.591042  52.0           0  \n",
       "15858         0.0  14.070298  20.0           0  \n",
       "...           ...        ...   ...         ...  \n",
       "23825         0.0  14.129904  42.0           1  \n",
       "23835         0.0  14.236778  42.0           1  \n",
       "23838         0.0  15.404106  42.0           1  \n",
       "23841         0.0  16.049837  29.0           1  \n",
       "23957         0.0   9.960063  53.0           1  \n",
       "\n",
       "[1237 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns not needed after adding new features\n",
    "\n",
    "columns_to_be_removed = ['DatoOprett', 'DatoOpdate']\n",
    "datacopy=datacopy.drop(columns_to_be_removed,axis='columns')\n",
    "datacopy[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "defensive-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = datacopy.nunique()\n",
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dietary-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating features set and target\n",
    "\n",
    "columns_to_be_removed = ['PipeStatus']\n",
    "data_features= datacopy.drop(columns_to_be_removed,axis='columns')\n",
    "columns_to_be_removed = ['ID','XKoordinat','YKoordinat','Depth','fra_kote','til_kote', 'Laengde','Fald','DiameterIn','MaterialeK','anlag_aar','TransportK','Funktionsk','TVObsKode','DatoSaneri','Age']\n",
    "data_target=datacopy.drop(columns_to_be_removed,axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "higher-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing NaNs: 1238\n",
      "Number of rows after removing NaNs: 1238\n"
     ]
    }
   ],
   "source": [
    "# data_fs= np.where(np.isnan(data_features))\n",
    "# data_fs\n",
    "data = datacopy\n",
    "print(\"Number of rows before removing NaNs: {}\".format(data.shape[0]))\n",
    "data = data.dropna()\n",
    "print(\"Number of rows after removing NaNs: {}\".format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-eating",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with train-test split and grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "lesbian-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data_target, stratify=data_target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "tracked-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 100\n",
      "Best penalty: l1\n",
      "Accuracy on training set: 0.986\n",
      "Accuracy on test set: 0.958\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune by cross validation\n",
    "\n",
    "C = [100, 10, 1.0, 0.1, 0.01]\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(C = C , penalty= penalty)\n",
    "\n",
    "#Create new logistic object\n",
    "logreg = LogisticRegression( solver = 'liblinear')\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(logreg, hyperparameters, cv=5,return_train_score=True, scoring=\"recall\")\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "    \n",
    "print(\"Accuracy on training set: {:.3f}\".format(best_model.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "toxic-heavy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       239\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.99      0.99      0.99       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9908656962696683"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create forest Object.\n",
    "a = best_model.best_estimator_.get_params()['C']\n",
    "b = best_model.best_estimator_.get_params()['penalty']\n",
    "\n",
    "logreg = LogisticRegression(C = a, penalty= b, solver = 'liblinear')\n",
    "\n",
    "#Create x and y variables.\n",
    "x = data_features\n",
    "y = data_target\n",
    "\n",
    "#Split data into training and testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "#Training the model.\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Predict test data set.\n",
    "y_pred =logreg.predict(X_test)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-negotiation",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with validation set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "starting-sword",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:696\n",
      "Size of validation set:232\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training, test and validation\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=43)\n",
    "print(\"Size of training set:{}\".format(X_train.shape[0]))\n",
    "print(\"Size of validation set:{}\".format(X_val.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "reasonable-evening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 100\n",
      "Best best_penalty found: l1\n",
      "Best score on validation set: 0.9956896551724138\n",
      "Score on training/validation set: 0.9989224137931034\n",
      "Score on test set: 0.9967741935483871\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        \n",
    "        # Learn the model\n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        logreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        score = logreg.score(X_val, y_val)\n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "                        \n",
    "\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C =best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best score on validation set: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "distinct-scale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       239\n",
      "           1       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           1.00       310\n",
      "   macro avg       1.00      0.99      1.00       310\n",
      "weighted avg       1.00      1.00      1.00       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9929577464788732"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-shanghai",
   "metadata": {},
   "source": [
    "# Tuning parameters with cross validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "assured-vintage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:696\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training and test , no validation data\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "print(\"Size of training set:{}\".format(X_train.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "characteristic-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 0.1\n",
      "Best best_penalty found: l1\n",
      "Best average score: 0.9913804126707353\n",
      "Score on training/validation set: 0.9924568965517241\n",
      "Score on test set: 0.9838709677419355\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        # Learn the model \n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        \n",
    "        # Perform cross validation\n",
    "        scores = cross_val_score(logreg, X_trainval, y_trainval, cv=5)\n",
    "        \n",
    "        # Compute the mean score\n",
    "        score = scores.mean()\n",
    "        \n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C=best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best average score: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fancy-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       239\n",
      "           1       1.00      0.93      0.96        71\n",
      "\n",
      "    accuracy                           0.98       310\n",
      "   macro avg       0.99      0.96      0.98       310\n",
      "weighted avg       0.98      0.98      0.98       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9647887323943662"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-tribute",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with train-test split and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "billion-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data_target, stratify=data_target, random_state=42)\n",
    "\n",
    "# preprocessing using 0-1 scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "polish-soviet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.1\n",
      "Best penalty: l1\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 1.000\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune by cross validation\n",
    "\n",
    "C = [100, 10, 1.0, 0.1, 0.01]\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(C = C , penalty= penalty)\n",
    "\n",
    "#Create new logistic object\n",
    "logreg = LogisticRegression( solver = 'liblinear')\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(logreg, hyperparameters, cv=5,return_train_score=True, scoring=\"recall\")\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "    \n",
    "print(\"Accuracy on training set: {:.3f}\".format(best_model.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(best_model.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "formal-lighting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       238\n",
      "           1       0.96      1.00      0.98        72\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.98      0.99      0.99       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9936974789915967"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create forest Object.\n",
    "a = best_model.best_estimator_.get_params()['C']\n",
    "b = best_model.best_estimator_.get_params()['penalty']\n",
    "\n",
    "logreg = LogisticRegression(C = a, penalty= b, solver = 'liblinear')\n",
    "\n",
    "#Training the model.\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict test data set.\n",
    "y_pred =logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-rubber",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with train-test split and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "reverse-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_features, data_target, stratify=data_target, random_state=42)\n",
    "\n",
    "# preprocessing using zero mean and unit variance scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "opposite-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.1\n",
      "Best penalty: l1\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 1.000\n"
     ]
    }
   ],
   "source": [
    "#List Hyperparameters that we want to tune by cross validation\n",
    "\n",
    "C = [100, 10, 1.0, 0.1, 0.01]\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(C = C , penalty= penalty)\n",
    "\n",
    "#Create new logistic object\n",
    "logreg = LogisticRegression( solver = 'liblinear')\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(logreg, hyperparameters, cv=5,return_train_score=True, scoring=\"recall\")\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "print('Best penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "    \n",
    "print(\"Accuracy on training set: {:.3f}\".format(best_model.score(X_train_scaled, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(best_model.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "greek-fiber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       238\n",
      "           1       0.96      1.00      0.98        72\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.98      0.99      0.99       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9936974789915967"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create forest Object.\n",
    "a = best_model.best_estimator_.get_params()['C']\n",
    "b = best_model.best_estimator_.get_params()['penalty']\n",
    "\n",
    "logreg = LogisticRegression(C = a, penalty= b, solver = 'liblinear')\n",
    "\n",
    "#Training the model.\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Predict test data set.\n",
    "y_pred =logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-kernel",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with validation set split and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "south-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:696\n",
      "Size of validation set:232\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training, test and validation\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=43)\n",
    "\n",
    "# preprocessing using 0-1 scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_trainval_scaled = scaler.transform( X_trainval)\n",
    "\n",
    "print(\"Size of training set:{}\".format(X_train_scaled.shape[0]))\n",
    "print(\"Size of validation set:{}\".format(X_val_scaled.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test_scaled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "strange-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 10\n",
      "Best best_penalty found: l1\n",
      "Best score on validation set: 0.9956896551724138\n",
      "Score on training/validation set: 0.9978448275862069\n",
      "Score on test set: 0.9870967741935484\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        \n",
    "        # Learn the model\n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        logreg.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        score = logreg.score(X_val_scaled, y_val)\n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "                        \n",
    "\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C =best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best score on validation set: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval_scaled, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "decreased-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       239\n",
      "           1       0.99      0.96      0.97        71\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.99      0.98      0.98       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9767811892274147"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-disabled",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with validation set split and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "laughing-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:696\n",
      "Size of validation set:232\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training, test and validation\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, random_state=43)\n",
    "\n",
    "# preprocessing using zero mean and unit variance scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_trainval_scaled = scaler.transform( X_trainval)\n",
    "\n",
    "print(\"Size of training set:{}\".format(X_train_scaled.shape[0]))\n",
    "print(\"Size of validation set:{}\".format(X_val_scaled.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test_scaled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "minute-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 100\n",
      "Best best_penalty found: l1\n",
      "Best score on validation set: 0.9956896551724138\n",
      "Score on training/validation set: 1.0\n",
      "Score on test set: 0.9903225806451613\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        \n",
    "        # Learn the model\n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        logreg.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        score = logreg.score(X_val_scaled, y_val)\n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "                        \n",
    "\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C =best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best score on validation set: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval_scaled, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "variable-harrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       239\n",
      "           1       1.00      0.96      0.98        71\n",
      "\n",
      "    accuracy                           0.99       310\n",
      "   macro avg       0.99      0.98      0.99       310\n",
      "weighted avg       0.99      0.99      0.99       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9788732394366197"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-burke",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with cross validation split and Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "virtual-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:928\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training and test , no validation data\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "\n",
    "# preprocessing using 0-1 scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_trainval_scaled = scaler.transform( X_trainval)\n",
    "\n",
    "\n",
    "print(\"Size of training set:{}\".format(X_trainval_scaled.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test_scaled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "promotional-medicare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 100\n",
      "Best best_penalty found: l1\n",
      "Best average score: 0.992444056960186\n",
      "Score on training/validation set: 1.0\n",
      "Score on test set: 0.9967741935483871\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        # Learn the model \n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        \n",
    "        # Perform cross validation\n",
    "        scores = cross_val_score(logreg, X_trainval_scaled, y_trainval, cv=5)\n",
    "        \n",
    "        # Compute the mean score\n",
    "        score = scores.mean()\n",
    "        \n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C=best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best average score: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval_scaled, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "integrated-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       239\n",
      "           1       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           1.00       310\n",
      "   macro avg       1.00      0.99      1.00       310\n",
      "weighted avg       1.00      1.00      1.00       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9929577464788732"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-conjunction",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters with cross validation split and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "historical-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:928\n",
      "Size of test set:310\n"
     ]
    }
   ],
   "source": [
    "# Divide the data into training and test , no validation data\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(data_features, data_target, random_state=42)\n",
    "\n",
    "# preprocessing using zero mean and unit variance scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_trainval_scaled = scaler.transform( X_trainval)\n",
    "\n",
    "\n",
    "print(\"Size of training set:{}\".format(X_trainval_scaled.shape[0]))\n",
    "print(\"Size of test set:{}\".format(X_test_scaled.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "beautiful-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best best_C found: 10\n",
      "Best best_penalty found: l1\n",
      "Best average score: 0.9902877070619006\n",
      "Score on training/validation set: 0.9989224137931034\n",
      "Score on test set: 0.9967741935483871\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "for C in [100, 10, 1.0, 0.1, 0.01, 0.001]:\n",
    "    for penalty in ['l1', 'l2']:\n",
    "        # Learn the model \n",
    "        logreg = LogisticRegression(penalty=penalty, C=C, solver = 'liblinear')\n",
    "        \n",
    "        # Perform cross validation\n",
    "        scores = cross_val_score(logreg, X_trainval_scaled, y_trainval, cv=5)\n",
    "        \n",
    "        # Compute the mean score\n",
    "        score = scores.mean()\n",
    "        \n",
    "        \n",
    "        # If improvement, store score and parameter\n",
    "        if score>best_score:\n",
    "            best_score = score\n",
    "            best_C = C\n",
    "            best_penalty= penalty\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "logreg = LogisticRegression(penalty= best_penalty, C=best_C, solver = 'liblinear')\n",
    "logreg.fit(X_trainval_scaled, y_trainval)\n",
    "\n",
    "print(\"Best best_C found: {}\".format(best_C))\n",
    "print(\"Best best_penalty found: {}\".format(best_penalty))\n",
    "print(\"Best average score: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(logreg.score(X_trainval_scaled, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(logreg.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "lyric-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       239\n",
      "           1       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           1.00       310\n",
      "   macro avg       1.00      0.99      1.00       310\n",
      "weighted avg       1.00      1.00      1.00       310\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9929577464788732"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test data set.\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "#Checking performance our model with classification report.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Checking performance our model with ROC Score.\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-pension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
